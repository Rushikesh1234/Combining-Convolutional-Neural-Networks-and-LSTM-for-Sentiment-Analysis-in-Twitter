{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval7Lakh_NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDRTkZVjJW9v",
        "outputId": "5b9c81f5-9e2a-497f-e1a3-b7d938450cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import all required packages\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "import keras \n",
        "from keras.models import Sequential, Model \n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Input, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in train data into a dataframe\n",
        "data = pd.read_csv(\"/content/training.1600000.processed.noemoticon.csv\", encoding=\"latin1\", header=None)\n",
        "print(data.shape)\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "uDhW8D_HJZjn",
        "outputId": "978f43af-e50d-4749-f99c-c2e1dff8aab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600000, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0           1                             2         3                4  \\\n",
              "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
              "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
              "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
              "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
              "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
              "\n",
              "                                                   5  \n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1  is upset that he can't update his Facebook by ...  \n",
              "2  @Kenichan I dived many times for the ball. Man...  \n",
              "3    my whole body feels itchy and like its on fire   \n",
              "4  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2624f830-985f-48c3-a844-206b294660bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2624f830-985f-48c3-a844-206b294660bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2624f830-985f-48c3-a844-206b294660bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2624f830-985f-48c3-a844-206b294660bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of tweets per sentiment in train Data\n",
        "\n",
        "print(data[0].value_counts())\n",
        "print(\"total \", len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pXx5dz0Kga4",
        "outputId": "19d0ae3d-46f6-43ce-8cd4-4f33529ff92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    800000\n",
            "4    800000\n",
            "Name: 0, dtype: int64\n",
            "total  1600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocess Function\n",
        "\n",
        "def dataPreprocess(text):\n",
        "\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "    u\"\\U00002702-\\U000027B0\"\n",
        "    u\"\\U000024C2-\\U0001F251\"\n",
        "    \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "    text = re.sub(u\"(\\u2018|\\u2019|u2018|u2019|u002)\", \"'\", text)\n",
        "\n",
        "    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    text = url_pattern.sub(r'', text)\n",
        "\n",
        "    taguser_pattern = re.compile('@(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    text = taguser_pattern.sub(r'', text)\n",
        "\n",
        "    contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
        "    specials = [\"’\", \"‘\", \"´\", \"`\", \"'\"]\n",
        "    for s in specials:\n",
        "        text = text.replace(s, \"'\")\n",
        "\n",
        "    for key in contraction_mapping:\n",
        "      text = text.lower()\n",
        "      text = text.replace(key, contraction_mapping[key])\n",
        "\n",
        "\n",
        "    textArr = text.split()\n",
        "    text = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))])\n",
        "\n",
        "    text = re.sub('[^a-zA-Z]',' ',text) \n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = text.split()\n",
        "    ps = PorterStemmer()\n",
        "    all_stopwords = stopwords.words('english')\n",
        "    all_stopwords.remove('not')\n",
        "    text = [ps.stem(word) for word in text if not word in set(all_stopwords)]\n",
        "\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "b1LqKQx6N3Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataPreprocess('@misstoriblack cool , i have no tweet apps  for my razr 2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXcjCp_pRy2O",
        "outputId": "7b0d1e36-10c1-45fb-8d2b-5a922e75016a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cool tweet app razr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputData = shuffle(data,random_state=42)\n",
        "inputData = inputData[1:700000]"
      ],
      "metadata": {
        "id": "nMgMNhYKOI3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputData[0].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHwWwb9uOQGT",
        "outputId": "da0cf5bc-100f-4c96-b801-43f6c24da780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    350003\n",
              "0    349996\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Proprocessing\n",
        "\n",
        "inputData[5] = inputData[5].apply(lambda x: dataPreprocess(x))"
      ],
      "metadata": {
        "id": "JCBuDo9aOSl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputData.to_csv(\"/content/preprocessed_data_semeval700000.csv\", index=False)"
      ],
      "metadata": {
        "id": "f99X1s_mPu4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cols = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "preprocessed_data = pd.read_csv('/content/preprocessed_data_semeval700000.csv', names=dataset_cols)\n",
        "\n",
        "# Remove null values from Dataframe\n",
        "preprocessed_data = preprocessed_data.dropna()\n",
        "\n",
        "print(preprocessed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXeUCAdUP7bd",
        "outputId": "913ebc39-43b9-4606-dc6b-fb1aa2d356ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        target         ids                          date      flag  \\\n",
            "0            0           1                             2         3   \n",
            "1            0  1467998485  Mon Apr 06 23:11:14 PDT 2009  NO_QUERY   \n",
            "2            0  2300048954  Tue Jun 23 13:40:11 PDT 2009  NO_QUERY   \n",
            "3            0  1993474027  Mon Jun 01 10:26:07 PDT 2009  NO_QUERY   \n",
            "4            0  2256550904  Sat Jun 20 12:56:51 PDT 2009  NO_QUERY   \n",
            "...        ...         ...                           ...       ...   \n",
            "699995       0  1975106381  Sat May 30 14:27:40 PDT 2009  NO_QUERY   \n",
            "699996       4  1974413652  Sat May 30 13:05:16 PDT 2009  NO_QUERY   \n",
            "699997       0  2252096148  Sat Jun 20 05:26:36 PDT 2009  NO_QUERY   \n",
            "699998       4  1970196461  Sat May 30 02:51:14 PDT 2009  NO_QUERY   \n",
            "699999       0  2263008538  Sat Jun 20 23:44:17 PDT 2009  NO_QUERY   \n",
            "\n",
            "                   user                                               text  \n",
            "0                     4                                                  5  \n",
            "1           sexygrneyes                                cool tweet app razr  \n",
            "2            sammydearr  know famili drama lame hey next time hang kim ...  \n",
            "3           Lamb_Leanne  school email not open geographi stuff revis st...  \n",
            "4           yogicerdito                               upper airway problem  \n",
            "...                 ...                                                ...  \n",
            "699995          Ninzorr  reciev email oberlin colleg titl quot tall sho...  \n",
            "699996      morganjoyce  got burnt suck fair later michel hous bunni ge...  \n",
            "699997  Alana_Eberhardt  good morn secondlif wake coffe get stuff done ...  \n",
            "699998            stu_b                                              thank  \n",
            "699999     AvonteNikole                    know need ass whoop playin like  \n",
            "\n",
            "[696112 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Y value (Predicted values)\n",
        "\n",
        "y = preprocessed_data['target']\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "Do1Qd-p-QF7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train-test dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data['text'], y, test_size = 0.15, random_state = 0)"
      ],
      "metadata": {
        "id": "w2QU3l7vQSxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform text into vector using TFIDF\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features = 600)\n",
        "X_train_tf = tfidf.fit_transform(X_train).toarray() \n",
        "X_test_tf = tfidf.transform(X_test).toarray()"
      ],
      "metadata": {
        "id": "J_XFkW_Jc87O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tf.shape, X_test_tf.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5sF7Ga4dApu",
        "outputId": "61d424bf-8e1a-430d-a4dc-515a0070d470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((591695, 600), (104417, 600), (591695,), (104417,))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial Distribution\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "MNB = MultinomialNB()\n",
        "\n",
        "y_pred = MNB.fit(X_train_tf, y_train).predict(X_test_tf)"
      ],
      "metadata": {
        "id": "-RF03yh2dVUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MNBscore = accuracy_score(y_test, y_pred)\n",
        "print(str('Total Accuracy {:04.2f}'.format((MNBscore)* 100))+'%')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eXuJJWddtAW",
        "outputId": "7d413cda-659b-404f-8660-d18dcb916609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracy 72.83%\n",
            "Confusion Matrix:\n",
            " [[38834 13525]\n",
            " [14843 37215]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.74      0.73     52359\n",
            "           1       0.73      0.71      0.72     52058\n",
            "\n",
            "    accuracy                           0.73    104417\n",
            "   macro avg       0.73      0.73      0.73    104417\n",
            "weighted avg       0.73      0.73      0.73    104417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complement Distribution\n",
        "\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "CNB = ComplementNB()\n",
        "\n",
        "y_pred = CNB.fit(X_train_tf, y_train).predict(X_test_tf)"
      ],
      "metadata": {
        "id": "nf90Qpe1f0ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNBscore = accuracy_score(y_test, y_pred)\n",
        "print(str('Total Accuracy {:04.2f}'.format((CNBscore)* 100))+'%')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D09Vy0y5gDlx",
        "outputId": "3405b915-685e-420e-c5bc-62d0d749e32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracy 72.83%\n",
            "Confusion Matrix:\n",
            " [[38827 13532]\n",
            " [14836 37222]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.74      0.73     52359\n",
            "           1       0.73      0.72      0.72     52058\n",
            "\n",
            "    accuracy                           0.73    104417\n",
            "   macro avg       0.73      0.73      0.73    104417\n",
            "weighted avg       0.73      0.73      0.73    104417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli Distribution\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "BNB = BernoulliNB()\n",
        "\n",
        "y_pred = BNB.fit(X_train_tf, y_train).predict(X_test_tf)"
      ],
      "metadata": {
        "id": "mdAhyvaPhFK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BNBscore = accuracy_score(y_test, y_pred)\n",
        "print(str('Total Accuracy {:04.2f}'.format((BNBscore)* 100))+'%')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgUj_AMXhOzL",
        "outputId": "61f88e3c-bbb4-4a0a-ac11-abe17d51dead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracy 73.82%\n",
            "Confusion Matrix:\n",
            " [[37257 15102]\n",
            " [12236 39822]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.71      0.73     52359\n",
            "           1       0.73      0.76      0.74     52058\n",
            "\n",
            "    accuracy                           0.74    104417\n",
            "   macro avg       0.74      0.74      0.74    104417\n",
            "weighted avg       0.74      0.74      0.74    104417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image  as mpimg\n",
        "\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r')\n",
        "plt.plot(epochs, val_loss, 'b')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Loss\", \"Validation Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "OfX3nmh-J9yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Distribution\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "GNB = GaussianNB()\n",
        "\n",
        "y_pred = GNB.fit(X_train_tf, y_train).predict(X_test_tf)"
      ],
      "metadata": {
        "id": "4Um7k-3vhcrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GNBscore = accuracy_score(y_test, y_pred)\n",
        "print(str('Total Accuracy {:04.2f}'.format((GNBscore)* 100))+'%')\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyP_zR8Qhl1t",
        "outputId": "4484a20e-66c7-4f15-8fff-0891589bb494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracy 70.31%\n",
            "Confusion Matrix:\n",
            " [[33842 18517]\n",
            " [12480 39578]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.65      0.69     52359\n",
            "           1       0.68      0.76      0.72     52058\n",
            "\n",
            "    accuracy                           0.70    104417\n",
            "   macro avg       0.71      0.70      0.70    104417\n",
            "weighted avg       0.71      0.70      0.70    104417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculated Accuracy\n",
        "\n",
        "print(str('MultinomialNB {:04.2f}'.format((MNBscore)* 100))+'%')\n",
        "print(str('ComplementNB {:04.2f}'.format((CNBscore)* 100))+'%')\n",
        "print(str('BernoulliNB {:04.2f}'.format((BNBscore)* 100))+'%')\n",
        "print(str('GaussianNB {:04.2f}'.format((GNBscore)* 100))+'%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7CsUUnQjIB9",
        "outputId": "d6f1db4a-2906-4b03-d5e6-66aab71df205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB 72.83%\n",
            "ComplementNB 72.83%\n",
            "BernoulliNB 73.82%\n",
            "GaussianNB 70.31%\n"
          ]
        }
      ]
    }
  ]
}